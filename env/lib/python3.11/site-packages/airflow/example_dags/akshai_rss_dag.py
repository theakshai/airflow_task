from airflow import DAG
from datetime import datetime
from airflow.operators.python_operator import PythonOperator
import requests
import pandas as pd
import csv
import sqlite3
import os
import xml.etree.ElementTree as ET


def download_rss_to_xml(file_path,**kwargs):
    url = "https://timesofindia.indiatimes.com/rssfeedstopstories.cms"
    response = requests.get(url) 
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    xml_file = os.path.join(file_path,f"rss_feed_xml{timestamp}.xml")

    with open(xml_file,'wb') as file:
        file.write(response.content)

    kwargs['ti'].xcom_push(key='rss_feed_xml',value=xml_file)
    kwargs['ti'].xcom_push(key='timestamp',value=timestamp)

def xml_to_csv(file_path,**kwargs):
    filename = kwargs['ti'].xcom_pull(key='rss_feed_xml')
    timestamp = kwargs['ti'].xcom_pull(key='timestamp')
    csv_file = os.path.join(file_path,f"rss_feed_csv{timestamp}.csv")

    tree = ET.parse(filename)
    root = tree.getroot()

    data = []

    for item in root.findall('.//item'):
        title = item.find('title').text
        link = item.find('link').text
        pub_date = item.find('pubDate').text

        data.append((title,link,pub_date))


    with open(csv_file, mode='w',newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['Title','Link','Publication Date'])
        writer.writerows(data);

    kwargs['ti'].xcom_push(key='rss_feed_csv',value=csv_file)



def csv_to_db(**kwargs):
    csv_file = kwargs['ti'].xcom_pull(key='rss_feed_csv')
    df = pd.read_csv(csv_file)
    conn = sqlite3.connect('/home/akshai/airflow/airflow.db') 
    cursor = conn.cursor()
    cursor.execute('''
                   CREATE TABLE IF NOT EXISTS rss_data(
                       Title TEXT,
                       Link TEXT,
                       Publication_Data TEXT
                       )
                   ''')
    df_values = df.values.tolist()
    cursor.executemany('INSERT INTO rss_data VALUES (?,?,?)', df_values)
    conn.commit()
    cursor.close()
    conn.close()



with DAG(
        "akshai_rss_dag",
        description="DAG to download rss to xml file push to xcom -> xml to csv -> csv to db",
        schedule_interval='@daily',
        start_date=datetime(2023, 7, 20),
        catchup=False,
        tags=["rss", "akshai", "timesofindia", "css", "db"],
) as dag:

    download_rss_to_xml_task = PythonOperator(
         task_id='download_rss_to_xml',
         python_callable=download_rss_to_xml,
         op_kwargs={'file_path': './rss_files/'},
         dag=dag,
    )

    xml_to_csv_task = PythonOperator(
         task_id='xml_to_csv',
         python_callable=xml_to_csv,
         op_kwargs={'file_path': './rss_files/'},
         dag=dag,
    )

    csv_to_db_task = PythonOperator(
         task_id='csv_to_db',
         python_callable=csv_to_db,
         dag=dag,
    )

download_rss_to_xml_task >> xml_to_csv_task >> csv_to_db_task  
